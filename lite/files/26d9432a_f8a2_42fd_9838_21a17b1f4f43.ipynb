{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "id": "57dd18b4",
            "cell_type": "markdown",
            "source": "<div class='alert alert-warning'>\n\nSciPy's interactive examples with Jupyterlite are experimental and may not always work as expected. Execution of cells containing imports may result in large downloads (up to 60MB of content for the first import from SciPy). Load times when importing from SciPy may take roughly 10-20 seconds. If you notice any problems, feel free to open an [issue](https://github.com/scipy/scipy/issues/new/choose).\n\n</div>",
            "metadata": {}
        },
        {
            "id": "01f8cf42",
            "cell_type": "markdown",
            "source": "Generate samples from a Latin hypercube generator.\n",
            "metadata": {}
        },
        {
            "id": "4655f10a",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy.stats import qmc\nsampler = qmc.LatinHypercube(d=2)\nsample = sampler.random(n=5)\nsample",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "array([[0.1545328 , 0.53664833], # random\n        [0.84052691, 0.06474907],\n        [0.52177809, 0.93343721],\n        [0.68033825, 0.36265316],\n        [0.26544879, 0.61163943]])"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "956047e2",
            "cell_type": "markdown",
            "source": "Compute the quality of the sample using the discrepancy criterion.\n",
            "metadata": {}
        },
        {
            "id": "9a4fa579",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "qmc.discrepancy(sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.0196... # random"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "b9ce360c",
            "cell_type": "markdown",
            "source": "Samples can be scaled to bounds.\n",
            "metadata": {}
        },
        {
            "id": "edf594e8",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "l_bounds = [0, 2]\nu_bounds = [10, 5]\nqmc.scale(sample, l_bounds, u_bounds)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "array([[1.54532796, 3.609945 ], # random\n        [8.40526909, 2.1942472 ],\n        [5.2177809 , 4.80031164],\n        [6.80338249, 3.08795949],\n        [2.65448791, 3.83491828]])"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "ac72c6cb",
            "cell_type": "markdown",
            "source": "Below are other examples showing alternative ways to construct LHS with\neven better coverage of the space.\n\nUsing a base LHS as a baseline.\n",
            "metadata": {}
        },
        {
            "id": "fbba8b2e",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "sampler = qmc.LatinHypercube(d=2)\nsample = sampler.random(n=5)\nqmc.discrepancy(sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.0196...  # random"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "e374193c",
            "cell_type": "markdown",
            "source": "Use the `optimization` keyword argument to produce a LHS with\nlower discrepancy at higher computational cost.\n",
            "metadata": {}
        },
        {
            "id": "b74d59f7",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "sampler = qmc.LatinHypercube(d=2, optimization=\"random-cd\")\nsample = sampler.random(n=5)\nqmc.discrepancy(sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.0176...  # random"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "72cddc78",
            "cell_type": "markdown",
            "source": "Use the `strength` keyword argument to produce an orthogonal array based\nLHS of strength 2. In this case, the number of sample points must be the\nsquare of a prime number.\n",
            "metadata": {}
        },
        {
            "id": "0342b543",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "sampler = qmc.LatinHypercube(d=2, strength=2)\nsample = sampler.random(n=9)\nqmc.discrepancy(sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.00526...  # random"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "ad43b53c",
            "cell_type": "markdown",
            "source": "Options could be combined to produce an optimized centered\northogonal array based LHS. After optimization, the result would not\nbe guaranteed to be of strength 2.\n\n**Real-world example**\n\nIn [9], a Latin Hypercube sampling (LHS) strategy was used to sample a\nparameter space to study the importance of each parameter of an epidemic\nmodel. Such analysis is also called a sensitivity analysis.\n\nSince the dimensionality of the problem is high (6), it is computationally\nexpensive to cover the space. When numerical experiments are costly, QMC\nenables analysis that may not be possible if using a grid.\n\nThe six parameters of the model represented the probability of illness,\nthe probability of withdrawal, and four contact probabilities. The\nauthors assumed uniform distributions for all parameters and generated\n50 samples.\n\nUsing `scipy.stats.qmc.LatinHypercube` to replicate the protocol,\nthe first step is to create a sample in the unit hypercube:\n",
            "metadata": {}
        },
        {
            "id": "db3c9dc5",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy.stats import qmc\nsampler = qmc.LatinHypercube(d=6)\nsample = sampler.random(n=50)",
            "outputs": []
        },
        {
            "id": "58edeafa",
            "cell_type": "markdown",
            "source": "Then the sample can be scaled to the appropriate bounds:\n",
            "metadata": {}
        },
        {
            "id": "735a4dc0",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "l_bounds = [0.000125, 0.01, 0.0025, 0.05, 0.47, 0.7]\nu_bounds = [0.000375, 0.03, 0.0075, 0.15, 0.87, 0.9]\nsample_scaled = qmc.scale(sample, l_bounds, u_bounds)",
            "outputs": []
        },
        {
            "id": "e089dab2",
            "cell_type": "markdown",
            "source": "Such a sample was used to run the model 50 times, and a polynomial\nresponse surface was constructed. This allowed the authors to study the\nrelative importance of each parameter across the range of possibilities\nof every other parameter.\n\nIn this computer experiment, they showed a 14-fold reduction in the\nnumber of samples required to maintain an error below 2% on their\nresponse surface when compared to a grid sampling.",
            "metadata": {}
        }
    ]
}