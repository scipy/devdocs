{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "id": "66e5b191",
            "cell_type": "markdown",
            "source": "<div class='alert alert-warning'>\n\nSciPy's interactive examples with Jupyterlite are experimental and may not always work as expected. Execution of cells containing imports may result in large downloads (up to 60MB of content for the first import from SciPy). Load times when importing from SciPy may take roughly 10-20 seconds. If you notice any problems, feel free to open an [issue](https://github.com/scipy/scipy/issues/new/choose).\n\n</div>",
            "metadata": {}
        },
        {
            "id": "da86d7ba",
            "cell_type": "markdown",
            "source": "Solve a linear regression problem via `fmin_l_bfgs_b`. To do this, first we\ndefine an objective function ``f(m, b) = (y - y_model)**2``, where `y`\ndescribes the observations and `y_model` the prediction of the linear model\nas ``y_model = m*x + b``. The bounds for the parameters, ``m`` and ``b``,\nare arbitrarily chosen as ``(0,5)`` and ``(5,10)`` for this example.\n",
            "metadata": {}
        },
        {
            "id": "380e6c25",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import numpy as np\nfrom scipy.optimize import fmin_l_bfgs_b\nX = np.arange(0, 10, 1)\nM = 2\nB = 3\nY = M * X + B\ndef func(parameters, *args):\n    x = args[0]\n    y = args[1]\n    m, b = parameters\n    y_model = m*x + b\n    error = sum(np.power((y - y_model), 2))\n    return error",
            "outputs": []
        },
        {
            "id": "a8ed4959",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "initial_values = np.array([0.0, 1.0])",
            "outputs": []
        },
        {
            "id": "c4914001",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "x_opt, f_opt, info = fmin_l_bfgs_b(func, x0=initial_values, args=(X, Y),\n                                   approx_grad=True)\nx_opt, f_opt",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "array([1.99999999, 3.00000006]), 1.7746231151323805e-14  # may vary"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "e0c27640",
            "cell_type": "markdown",
            "source": "The optimized parameters in ``x_opt`` agree with the ground truth parameters\n``m`` and ``b``. Next, let us perform a bound constrained optimization using\nthe `bounds` parameter.\n",
            "metadata": {}
        },
        {
            "id": "e4c44a95",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "bounds = [(0, 5), (5, 10)]\nx_opt, f_op, info = fmin_l_bfgs_b(func, x0=initial_values, args=(X, Y),\n                                  approx_grad=True, bounds=bounds)\nx_opt, f_opt",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "array([1.65990508, 5.31649385]), 15.721334516453945  # may vary"
                    },
                    "execution_count": null
                }
            ]
        }
    ]
}